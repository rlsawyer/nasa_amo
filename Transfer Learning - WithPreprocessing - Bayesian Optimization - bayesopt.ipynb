{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications import (VGG16, InceptionV3, ResNet50, VGG19, Xception, InceptionResNetV2, DenseNet201, \n",
    "NASNetMobile, NASNetLarge, MobileNet)\n",
    "\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_flag = 1\n",
    "pool = None\n",
    "\n",
    "if model_flag == 1:\n",
    "    vgg_conv = VGG16(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3),\n",
    "                      pooling=pool)\n",
    "    vgg_conv.summary()\n",
    "elif model_flag == 2:\n",
    "    inc_conv = InceptionV3(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 3:\n",
    "    resnet_conv = ResNet50(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 4:\n",
    "    vgg19_conv = VGG19(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 5:\n",
    "    xcep_conv = Xception(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(299,299,3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 6:\n",
    "    inc_res_conv = InceptionResNetV2(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(299,299,3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 7:\n",
    "    dense201_conv = DenseNet201(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 8:\n",
    "    nasnet_conv = NASNetMobile(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 9:\n",
    "    nasnet_conv = NASNetLarge(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(331, 331, 3),\n",
    "                      pooling=pool)\n",
    "elif model_flag == 10:\n",
    "    mobilenet_conv = MobileNet(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3),\n",
    "                      pooling=pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1829 images belonging to 2 classes.\n",
      "Obtaining training data\n",
      "0\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/home/rlee/Documents/Pneumothorax/model/mmode/train'\n",
    "validation_dir = '/home/rlee/Documents/Pneumothorax/model/mmode/val'\n",
    "\n",
    "nTrain = 1829\n",
    "nVal = 457\n",
    "\n",
    "if model_flag == 5 or model_flag == 6:\n",
    "    datagen = ImageDataGenerator(rescale=1./255,data_format=\"channels_last\")\n",
    "    target_sz = 299\n",
    "elif model_flag == 9:\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    target_sz = 331\n",
    "else:\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    target_sz = 224\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "if model_flag == 1:\n",
    "    d1 = 7\n",
    "    d2 = 7\n",
    "    d3 = 512\n",
    "    model_name = 'VGG16'\n",
    "elif model_flag == 2:\n",
    "    d1 = 5\n",
    "    d2 = 5\n",
    "    d3 = 2048\n",
    "    model_name = 'InceptionV3'\n",
    "elif model_flag == 3:\n",
    "    d1 = 1\n",
    "    d2 = 1\n",
    "    d3 = 2048\n",
    "    model_name = 'Resnet50'\n",
    "elif model_flag == 4:\n",
    "    d1 = 7\n",
    "    d2 = 7\n",
    "    d3 = 512\n",
    "    model_name = 'VGG19'\n",
    "elif model_flag == 5:\n",
    "    d1 = 10\n",
    "    d2 = 10\n",
    "    d3 = 2048\n",
    "    model_name = 'Xception'\n",
    "elif model_flag == 6:\n",
    "    d1 = 8\n",
    "    d2 = 8\n",
    "    d3 = 1536\n",
    "    model_name = 'InceptionResNetV2'\n",
    "elif model_flag == 7:\n",
    "    d1 = 7\n",
    "    d2 = 7\n",
    "    d3 = 1920\n",
    "    model_name = 'DenseNet201'\n",
    "elif model_flag == 8:\n",
    "    d1 = 7\n",
    "    d2 = 7\n",
    "    d3 = 1056\n",
    "    model_name = 'NASNetMobile'\n",
    "elif model_flag == 9:\n",
    "    d1 = 11\n",
    "    d2 = 11\n",
    "    d3 = 4032\n",
    "    model_name = 'NASNetLarge'\n",
    "elif model_flag == 10:\n",
    "    d1 = 7\n",
    "    d2 = 7\n",
    "    d3 = 1024\n",
    "    model_name = 'MobileNet'\n",
    "    \n",
    "if pool is not None:\n",
    "    d1 = 1\n",
    "    d2 = 1\n",
    "    \n",
    "train_features = np.zeros(shape=(nTrain, d1, d2, d3))\n",
    "\n",
    "train_labels = np.zeros(shape=(nTrain,2))\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(target_sz, target_sz),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "print('Obtaining training data')\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    if i%50 == 0:\n",
    "        print(i)\n",
    "    if model_flag == 1:\n",
    "        features_batch = vgg_conv.predict(inputs_batch)\n",
    "    elif model_flag == 2:\n",
    "        features_batch = inc_conv.predict(inputs_batch)\n",
    "    elif model_flag == 3:\n",
    "        features_batch = resnet_conv.predict(inputs_batch)\n",
    "    elif model_flag == 4:\n",
    "        features_batch = vgg19_conv.predict(inputs_batch)        \n",
    "    elif model_flag == 5:\n",
    "        features_batch = xcep_conv.predict(inputs_batch) \n",
    "    elif model_flag == 6:\n",
    "        features_batch = inc_res_conv.predict(inputs_batch) \n",
    "    elif model_flag == 7:\n",
    "        features_batch = dense201_conv.predict(inputs_batch) \n",
    "    elif model_flag == 8 or model_flag == 9:\n",
    "        features_batch = nasnet_conv.predict(inputs_batch) \n",
    "    elif model_flag == 10:\n",
    "        features_batch = mobilenet_conv.predict(inputs_batch) \n",
    "    #print(features_batch.shape)\n",
    "    b_sz = features_batch.shape[0]\n",
    "\n",
    "    if features_batch.shape[0] < batch_size:\n",
    "        train_features[i * batch_size : i * batch_size + b_sz] = np.reshape(features_batch, (b_sz,d1,d2,d3))\n",
    "        train_labels[i * batch_size : i * batch_size + b_sz] = labels_batch\n",
    "    else:\n",
    "        train_features[i * batch_size : (i + 1) * batch_size] = np.reshape(features_batch, (batch_size,d1,d2,d3))\n",
    "        train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= nTrain:\n",
    "        break\n",
    "\n",
    "\n",
    "train_features = np.reshape(train_features, (nTrain, d1 * d2 * d3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 457 images belonging to 2 classes.\n",
      "Obtaining validation data\n"
     ]
    }
   ],
   "source": [
    "validation_features = np.zeros(shape=(nVal, d1, d2, d3))\n",
    "\n",
    "validation_labels = np.zeros(shape=(nVal,2))\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(target_sz, target_sz),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "print('Obtaining validation data')\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in validation_generator:\n",
    "    if model_flag == 1:\n",
    "        features_batch = vgg_conv.predict(inputs_batch)\n",
    "    elif model_flag == 2:\n",
    "        features_batch = inc_conv.predict(inputs_batch)\n",
    "    elif model_flag == 3:\n",
    "        features_batch = resnet_conv.predict(inputs_batch)    \n",
    "    elif model_flag == 4:\n",
    "        features_batch = vgg19_conv.predict(inputs_batch)        \n",
    "    elif model_flag == 5:\n",
    "        features_batch = xcep_conv.predict(inputs_batch) \n",
    "    elif model_flag == 6:\n",
    "        features_batch = inc_res_conv.predict(inputs_batch) \n",
    "    elif model_flag == 7:\n",
    "        features_batch = dense201_conv.predict(inputs_batch) \n",
    "    elif model_flag == 8 or model_flag == 9:\n",
    "        features_batch = nasnet_conv.predict(inputs_batch) \n",
    "    elif model_flag == 10:\n",
    "        features_batch = mobilenet_conv.predict(inputs_batch) \n",
    "    \n",
    "    b_sz = features_batch.shape[0]\n",
    "\n",
    "    if features_batch.shape[0] < batch_size:\n",
    "        validation_features[i * batch_size : i * batch_size + b_sz] = np.reshape(features_batch, (b_sz,d1,d2,d3))\n",
    "        validation_labels[i * batch_size : i * batch_size + b_sz] = labels_batch\n",
    "    else:\n",
    "        validation_features[i * batch_size : (i + 1) * batch_size] = np.reshape(features_batch, (batch_size,d1,d2,d3))\n",
    "        validation_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        \n",
    "    i += 1\n",
    "    if i * batch_size >= nVal:\n",
    "        break\n",
    "\n",
    "validation_features = np.reshape(validation_features, (nVal, d1 * d2 * d3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers, initializers, regularizers, callbacks\n",
    "\n",
    "activ = 'relu'\n",
    "loss = 'categorical_crossentropy'\n",
    "optim = 1\n",
    "init = initializers.random_normal()#initializers.glorot_normal()\n",
    "bnorm_flag = False\n",
    "model_save_folder = 'saved_models'\n",
    "if not os.path.isdir(model_save_folder):\n",
    "    os.mkdir(model_save_folder)\n",
    "\n",
    "itr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model():\n",
    "    def __init__(self, drpout, init, activ, bnorm_flag, lrt, loss, optim, decay_rt, decay_steps, \n",
    "                 batch_size, n_epochs, train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "        self.drpout = drpout\n",
    "        self.init = init\n",
    "        self.activ = activ\n",
    "        self.bnorm_flag = bnorm_flag\n",
    "        self.lrt = lrt\n",
    "        self.loss = loss\n",
    "        self.optim = optim\n",
    "        self.decay_rt = decay_rt\n",
    "        self.decay_steps = np.max([np.round(decay_steps*n_epochs), 1])\n",
    "        print('decay step percentage', decay_steps)\n",
    "        print('decay steps', self.decay_steps)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        self.val_X = val_X\n",
    "        self.val_y = val_y        \n",
    "        self.test_X = test_X\n",
    "        self.test_y = test_y\n",
    "        self.model = self.set_up_model()\n",
    "        \n",
    "    def set_up_model(self):\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        \n",
    "        '''\n",
    "        if self.init == 0:\n",
    "            init = initializers.RandomNormal()\n",
    "        else:\n",
    "            init = initializers.glorot_normal()\n",
    "        \n",
    "        activ = 'relu'\n",
    "        if self.activ == 1:\n",
    "            activ = 'relu'\n",
    "        elif self.activ == 2:\n",
    "            activ = 'tanh'\n",
    "        elif self.activ == 3:\n",
    "            activ = 'sigmoid'\n",
    "            \n",
    "        if self.loss == 1:\n",
    "            loss = 'categorical_crossentropy'\n",
    "        elif self.loss == 2:\n",
    "            loss = 'mean_squared_error'\n",
    "        elif self.loss == 3:\n",
    "            loss = 'kullback_leibler_divergence'\n",
    "        elif self.loss == 4:\n",
    "            loss = 'categorical_hinge'\n",
    "        '''\n",
    "        \n",
    "        model.add(layers.Dense(d3, activation=self.activ, input_dim=d1 * d2 * d3, kernel_initializer=self.init))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "        if self.bnorm_flag:\n",
    "            model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(self.drpout))\n",
    "        model.add(layers.Dense(2, activation='softmax', kernel_initializer=self.init))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "        \n",
    "        optim = optimizers.RMSprop(lr=self.lrt)\n",
    "        if self.optim == 1:\n",
    "            optim = optimizers.RMSprop(lr=self.lrt)\n",
    "        elif self.optim == 2:\n",
    "            optim = optimizers.Adam(lr=self.lrt)\n",
    "        elif self.optim == 3:\n",
    "            optim = optimizers.SGD(lr=self.lrt)\n",
    "            \n",
    "        model.compile(optimizer=optim, loss=loss, metrics=['acc'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def step_decay(self, epoch):\n",
    "            steps = self.decay_steps#np.floor(n_epochs/3)\n",
    "            lrate = self.lrt * (self.decay_rt)**np.floor(epoch/steps)\n",
    "            return lrate\n",
    "        \n",
    "    def train_model(self, save_folder):\n",
    "        global itr\n",
    "        earlystop = EarlyStopping(patience=10)\n",
    "        checkpointer = callbacks.ModelCheckpoint(filepath=save_folder+'/weights'+str(itr)+'.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        lrate=keras.callbacks.LearningRateScheduler(self.step_decay,verbose=1)\n",
    "        callbacks_list = [earlystop, lrate, checkpointer]\n",
    "        history = self.model.fit(self.train_X,\n",
    "                self.train_y,\n",
    "                epochs=self.n_epochs,\n",
    "                callbacks=callbacks_list,\n",
    "                batch_size=self.batch_size,\n",
    "                validation_data=(self.val_X,self.val_y))\n",
    "        #dscr_phrase = 'rmsprop' + str(lrt) + 'decay_' + str(decay_rt) + '_' + loss + 'glorot_normal_init'# + 'dropout_' + str(drpout)\n",
    "        #model.save(model_name + '_mmode_nopreprocessing_' + dscr_phrase + '.h5')\n",
    "        self.model = keras.models.load_model(save_folder+'/weights'+str(itr)+'.hdf5')\n",
    "        \n",
    "    def model_evaluate(self, save_folder):\n",
    "        self.train_model(save_folder)\n",
    "        \n",
    "        evaluation = self.model.evaluate(self.test_X, self.test_y, batch_size=self.batch_size, verbose=0)\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_my_model(drpout, init, activ, bnorm_flag, lrt, loss, optim, decay_rt, decay_steps, \n",
    "                 batch_size, n_epochs, train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "    \n",
    "    model = my_model(drpout=drpout, init=init, activ=activ, bnorm_flag=bnorm_flag, lrt=lrt, loss=loss, \n",
    "                     optim=optim, decay_rt=decay_rt, decay_steps=decay_steps, batch_size=batch_size, \n",
    "                     n_epochs=n_epochs, train_X=train_X, train_y=train_y, val_X=val_X, val_y=val_y, \n",
    "                     test_X=test_X, test_y=test_y)\n",
    "    model_evaluation = model.model_evaluate(model_save_folder)\n",
    "    return model_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds for hyper-parameters in model\n",
    "bounds = {'drpout': (0.0, 0.8),\n",
    "          'lrt': (1e-5, 1e-3),\n",
    "          'decay_rt': (1e-6, 1.0),\n",
    "          'decay_steps': (0.05, 0.5),\n",
    "          'batch_size': (16, 128),\n",
    "          'n_epochs': (20, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(drpout, lrt, decay_rt, decay_steps, batch_size, n_epochs):\n",
    "    global itr\n",
    "    itr += 1\n",
    "    print('iteration:',itr)\n",
    "    global all_params\n",
    "    params ={'drpout': drpout, 'decay_steps': decay_steps, 'n_epochs': n_epochs, 'lrt': lrt, 'batch_size': batch_size, 'decay_rt': decay_rt}\n",
    "    all_params.append(params)\n",
    "    evaluation = run_my_model(drpout=drpout, init=init, activ=activ, bnorm_flag=bnorm_flag, \n",
    "                              lrt=lrt, loss=loss, optim=optim, decay_rt=decay_rt, \n",
    "                                        decay_steps=decay_steps, batch_size=int(batch_size), n_epochs=int(n_epochs),\n",
    "                             train_X=train_features, train_y=train_labels, val_X=validation_features,\n",
    "                             val_y=validation_labels, test_X=validation_features, test_y=validation_labels)\n",
    "    print(\"LOSS:\\t{0} \\t ACCURACY:\\t{1}\".format(evaluation[0], evaluation[1]))\n",
    "    print(evaluation)\n",
    "    return evaluation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   batch_size |   decay_rt |   decay_steps |    drpout |       lrt |   n_epochs | \n",
      "iteration: 1\n",
      "decay step percentage 0.261683915814954\n",
      "decay steps 9.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/35\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 7.5681 - acc: 0.5046 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.97088, saving model to saved_models/weights1.hdf5\n",
      "Epoch 2/35\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/35\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/35\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/35\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/35\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/35\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/35\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/35\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00048796818345145187.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/35\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0004462916246182609.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/35\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0004462916246182609.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "LOSS:\t7.970876103417878 \t ACCURACY:\t0.5054704596490255\n",
      "[7.970876103417878, 0.5054704596490255]\n",
      "    1 | 00m45s | \u001b[35m   0.50547\u001b[0m | \u001b[32m    120.5189\u001b[0m | \u001b[32m    0.9146\u001b[0m | \u001b[32m       0.2617\u001b[0m | \u001b[32m   0.0809\u001b[0m | \u001b[32m   0.0005\u001b[0m | \u001b[32m   35.1463\u001b[0m | \n",
      "iteration: 2\n",
      "decay step percentage 0.36202255763276514\n",
      "decay steps 30.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/84\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 4.4329 - acc: 0.5878 - val_loss: 1.5259 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.52594, saving model to saved_models/weights2.hdf5\n",
      "Epoch 2/84\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 1.1518 - acc: 0.7879 - val_loss: 0.7830 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.52594 to 0.78295, saving model to saved_models/weights2.hdf5\n",
      "Epoch 3/84\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.7303 - acc: 0.8332 - val_loss: 0.3732 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78295 to 0.37319, saving model to saved_models/weights2.hdf5\n",
      "Epoch 4/84\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.4743 - acc: 0.8409 - val_loss: 0.2676 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37319 to 0.26756, saving model to saved_models/weights2.hdf5\n",
      "Epoch 5/84\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2619 - acc: 0.8890 - val_loss: 0.4769 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/84\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.3218 - acc: 0.8753 - val_loss: 0.2724 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/84\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2248 - acc: 0.9071 - val_loss: 0.6250 - val_acc: 0.7505\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/84\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.3468 - acc: 0.8715 - val_loss: 0.1388 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.26756 to 0.13883, saving model to saved_models/weights2.hdf5\n",
      "Epoch 9/84\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1761 - acc: 0.9256 - val_loss: 0.1315 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13883 to 0.13146, saving model to saved_models/weights2.hdf5\n",
      "Epoch 10/84\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2656 - acc: 0.8972 - val_loss: 0.1459 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/84\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2558 - acc: 0.9114 - val_loss: 0.2601 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/84\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1851 - acc: 0.9311 - val_loss: 0.2212 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/84\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1732 - acc: 0.9311 - val_loss: 0.2468 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/84\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1453 - acc: 0.9431 - val_loss: 0.4518 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/84\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2360 - acc: 0.9202 - val_loss: 0.1266 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.13146 to 0.12661, saving model to saved_models/weights2.hdf5\n",
      "Epoch 16/84\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1389 - acc: 0.9431 - val_loss: 0.2345 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/84\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1781 - acc: 0.9306 - val_loss: 0.3266 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/84\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1399 - acc: 0.9404 - val_loss: 0.3784 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/84\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1729 - acc: 0.9382 - val_loss: 0.1328 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/84\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1525 - acc: 0.9404 - val_loss: 0.1299 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/84\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0993 - acc: 0.9628 - val_loss: 0.1057 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.12661 to 0.10572, saving model to saved_models/weights2.hdf5\n",
      "Epoch 22/84\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1693 - acc: 0.9344 - val_loss: 0.1192 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/84\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1425 - acc: 0.9448 - val_loss: 0.1184 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/84\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1208 - acc: 0.9524 - val_loss: 0.3495 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/84\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0899 - acc: 0.9590 - val_loss: 0.1101 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/84\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.1659 - acc: 0.9437 - val_loss: 0.1618 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/84\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0881 - acc: 0.9628 - val_loss: 0.1151 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/84\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1099 - acc: 0.9634 - val_loss: 0.2627 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/84\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.1467 - acc: 0.9470 - val_loss: 0.1991 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/84\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0005895537162139697.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1013 - acc: 0.9617 - val_loss: 0.1403 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/84\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.00021224418703269087.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0715 - acc: 0.9716 - val_loss: 0.1085 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "LOSS:\t0.10572042904745306 \t ACCURACY:\t0.9540481275228755\n",
      "[0.10572042904745306, 0.9540481275228755]\n",
      "    2 | 01m43s | \u001b[35m   0.95405\u001b[0m | \u001b[32m    124.1222\u001b[0m | \u001b[32m    0.3600\u001b[0m | \u001b[32m       0.3620\u001b[0m | \u001b[32m   0.6704\u001b[0m | \u001b[32m   0.0006\u001b[0m | \u001b[32m   84.7077\u001b[0m | \n",
      "iteration: 3\n",
      "decay step percentage 0.14498230259117567\n",
      "decay steps 14.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/95\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 7.8849 - acc: 0.4970 - val_loss: 4.6144 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.61439, saving model to saved_models/weights3.hdf5\n",
      "Epoch 2/95\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.8348 - acc: 0.7490 - val_loss: 0.4748 - val_acc: 0.7571\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.61439 to 0.47476, saving model to saved_models/weights3.hdf5\n",
      "Epoch 3/95\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.4024 - acc: 0.8584 - val_loss: 0.5620 - val_acc: 0.7549\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/95\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.2923 - acc: 0.8972 - val_loss: 0.9031 - val_acc: 0.7856\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/95\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2353 - acc: 0.9136 - val_loss: 0.1342 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.47476 to 0.13420, saving model to saved_models/weights3.hdf5\n",
      "Epoch 6/95\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.2011 - acc: 0.9289 - val_loss: 0.1551 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/95\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 6s 4ms/step - loss: 0.1517 - acc: 0.9453 - val_loss: 0.3170 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/95\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1621 - acc: 0.9431 - val_loss: 0.1123 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.13420 to 0.11230, saving model to saved_models/weights3.hdf5\n",
      "Epoch 9/95\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1332 - acc: 0.9546 - val_loss: 0.1079 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11230 to 0.10787, saving model to saved_models/weights3.hdf5\n",
      "Epoch 10/95\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1047 - acc: 0.9595 - val_loss: 0.1503 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/95\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1331 - acc: 0.9497 - val_loss: 0.1091 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/95\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0772 - acc: 0.9677 - val_loss: 0.1241 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/95\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.1135 - acc: 0.9574 - val_loss: 0.2785 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/95\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00019603936348784387.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0941 - acc: 0.9590 - val_loss: 0.1190 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/95\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0387 - acc: 0.9858 - val_loss: 0.0927 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.10787 to 0.09269, saving model to saved_models/weights3.hdf5\n",
      "Epoch 16/95\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0327 - acc: 0.9869 - val_loss: 0.0963 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/95\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0293 - acc: 0.9902 - val_loss: 0.0898 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09269 to 0.08975, saving model to saved_models/weights3.hdf5\n",
      "Epoch 18/95\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 5s 2ms/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0984 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/95\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0244 - acc: 0.9902 - val_loss: 0.0898 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/95\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0271 - acc: 0.9913 - val_loss: 0.0854 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08975 to 0.08543, saving model to saved_models/weights3.hdf5\n",
      "Epoch 21/95\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0238 - acc: 0.9923 - val_loss: 0.0885 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/95\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0236 - acc: 0.9913 - val_loss: 0.0872 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/95\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0206 - acc: 0.9929 - val_loss: 0.0953 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/95\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0223 - acc: 0.9940 - val_loss: 0.0879 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/95\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0192 - acc: 0.9956 - val_loss: 0.0965 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/95\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0171 - acc: 0.9962 - val_loss: 0.0877 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/95\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0166 - acc: 0.9962 - val_loss: 0.0823 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08543 to 0.08233, saving model to saved_models/weights3.hdf5\n",
      "Epoch 28/95\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 4.28509745429586e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0162 - acc: 0.9962 - val_loss: 0.0890 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/95\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0141 - acc: 0.9978 - val_loss: 0.0864 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/95\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0120 - acc: 0.9989 - val_loss: 0.0866 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/95\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0838 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/95\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0106 - acc: 0.9984 - val_loss: 0.0862 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/95\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0109 - acc: 0.9989 - val_loss: 0.0854 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/95\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0123 - acc: 0.9989 - val_loss: 0.0922 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/95\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0118 - acc: 0.9978 - val_loss: 0.0823 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/95\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0115 - acc: 0.9978 - val_loss: 0.0836 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/95\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 9.366516941354723e-06.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0102 - acc: 0.9989 - val_loss: 0.0844 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "LOSS:\t0.08232978248410334 \t ACCURACY:\t0.9649890609069257\n",
      "[0.08232978248410334, 0.9649890609069257]\n",
      "    3 | 03m53s | \u001b[35m   0.96499\u001b[0m | \u001b[32m     47.2748\u001b[0m | \u001b[32m    0.2186\u001b[0m | \u001b[32m       0.1450\u001b[0m | \u001b[32m   0.1479\u001b[0m | \u001b[32m   0.0002\u001b[0m | \u001b[32m   95.8574\u001b[0m | \n",
      "iteration: 4\n",
      "decay step percentage 0.26511727395704116\n",
      "decay steps 23.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/87\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 7.5589 - acc: 0.5134 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.97088, saving model to saved_models/weights4.hdf5\n",
      "Epoch 2/87\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/87\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/87\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/87\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/87\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/87\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/87\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/87\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/87\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/87\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0006204317377924083.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 7.9753 - acc: 0.5052 - val_loss: 7.9709 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "LOSS:\t7.970875231911891 \t ACCURACY:\t0.5054704574317849\n",
      "[7.970875231911891, 0.5054704574317849]\n",
      "    4 | 00m40s |    0.50547 |     103.5944 |     0.1893 |        0.2651 |    0.2444 |    0.0006 |    87.9070 | \n",
      "iteration: 5\n",
      "decay step percentage 0.239930297815377\n",
      "decay steps 22.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/91\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 1.3124 - acc: 0.6102 - val_loss: 0.3349 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33492, saving model to saved_models/weights5.hdf5\n",
      "Epoch 2/91\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.5798 - acc: 0.7687 - val_loss: 0.3142 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33492 to 0.31417, saving model to saved_models/weights5.hdf5\n",
      "Epoch 3/91\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.4245 - acc: 0.8393 - val_loss: 0.6502 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/91\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.3249 - acc: 0.8688 - val_loss: 0.1621 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31417 to 0.16213, saving model to saved_models/weights5.hdf5\n",
      "Epoch 5/91\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2915 - acc: 0.8917 - val_loss: 0.1495 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16213 to 0.14952, saving model to saved_models/weights5.hdf5\n",
      "Epoch 6/91\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2684 - acc: 0.8989 - val_loss: 0.1316 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14952 to 0.13164, saving model to saved_models/weights5.hdf5\n",
      "Epoch 7/91\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2745 - acc: 0.8967 - val_loss: 0.4961 - val_acc: 0.8446\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/91\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2171 - acc: 0.9207 - val_loss: 0.3112 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/91\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1754 - acc: 0.9306 - val_loss: 0.1377 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/91\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1714 - acc: 0.9338 - val_loss: 0.1407 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/91\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1632 - acc: 0.9377 - val_loss: 0.1658 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/91\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1335 - acc: 0.9502 - val_loss: 0.1578 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/91\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1494 - acc: 0.9431 - val_loss: 0.1760 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/91\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1403 - acc: 0.9502 - val_loss: 0.2544 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/91\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1434 - acc: 0.9410 - val_loss: 0.2762 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/91\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 7.633619557662035e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1075 - acc: 0.9563 - val_loss: 0.2076 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "LOSS:\t0.1316399591072122 \t ACCURACY:\t0.9496717741244209\n",
      "[0.1316399591072122, 0.9496717741244209]\n",
      "    5 | 00m56s |    0.94967 |     105.3756 |     0.2004 |        0.2399 |    0.1805 |    0.0001 |    91.7881 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   batch_size |   decay_rt |   decay_steps |    drpout |       lrt |   n_epochs | \n",
      "iteration: 6\n",
      "decay step percentage 0.05\n",
      "decay steps 5.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.6180 - acc: 0.6698 - val_loss: 0.4925 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49253, saving model to saved_models/weights6.hdf5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.4442 - acc: 0.8157 - val_loss: 0.4306 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49253 to 0.43060, saving model to saved_models/weights6.hdf5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.3775 - acc: 0.8535 - val_loss: 0.3484 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43060 to 0.34841, saving model to saved_models/weights6.hdf5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.3193 - acc: 0.8885 - val_loss: 0.3478 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34841 to 0.34780, saving model to saved_models/weights6.hdf5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2836 - acc: 0.9060 - val_loss: 0.2827 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34780 to 0.28271, saving model to saved_models/weights6.hdf5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2580 - acc: 0.9136 - val_loss: 0.2430 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28271 to 0.24295, saving model to saved_models/weights6.hdf5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2298 - acc: 0.9317 - val_loss: 0.2473 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.2111 - acc: 0.9273 - val_loss: 0.2165 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.24295 to 0.21650, saving model to saved_models/weights6.hdf5\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1928 - acc: 0.9382 - val_loss: 0.1991 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.21650 to 0.19915, saving model to saved_models/weights6.hdf5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1836 - acc: 0.9459 - val_loss: 0.1852 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19915 to 0.18516, saving model to saved_models/weights6.hdf5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1700 - acc: 0.9453 - val_loss: 0.2176 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1607 - acc: 0.9513 - val_loss: 0.1701 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18516 to 0.17014, saving model to saved_models/weights6.hdf5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1521 - acc: 0.9524 - val_loss: 0.1666 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17014 to 0.16663, saving model to saved_models/weights6.hdf5\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1465 - acc: 0.9546 - val_loss: 0.1605 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.16663 to 0.16051, saving model to saved_models/weights6.hdf5\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1373 - acc: 0.9595 - val_loss: 0.1583 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16051 to 0.15825, saving model to saved_models/weights6.hdf5\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1321 - acc: 0.9606 - val_loss: 0.1689 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1288 - acc: 0.9584 - val_loss: 0.1658 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1243 - acc: 0.9617 - val_loss: 0.1971 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1200 - acc: 0.9666 - val_loss: 0.1523 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15825 to 0.15233, saving model to saved_models/weights6.hdf5\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1160 - acc: 0.9650 - val_loss: 0.1501 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15233 to 0.15011, saving model to saved_models/weights6.hdf5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1099 - acc: 0.9677 - val_loss: 0.1343 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15011 to 0.13433, saving model to saved_models/weights6.hdf5\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1087 - acc: 0.9650 - val_loss: 0.1733 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1059 - acc: 0.9672 - val_loss: 0.1554 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1022 - acc: 0.9677 - val_loss: 0.1289 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.13433 to 0.12890, saving model to saved_models/weights6.hdf5\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0998 - acc: 0.9688 - val_loss: 0.1396 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0962 - acc: 0.9710 - val_loss: 0.1257 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12890 to 0.12569, saving model to saved_models/weights6.hdf5\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0945 - acc: 0.9710 - val_loss: 0.1289 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0921 - acc: 0.9732 - val_loss: 0.1220 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12569 to 0.12196, saving model to saved_models/weights6.hdf5\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0900 - acc: 0.9727 - val_loss: 0.1205 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.12196 to 0.12054, saving model to saved_models/weights6.hdf5\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0885 - acc: 0.9738 - val_loss: 0.1282 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0878 - acc: 0.9721 - val_loss: 0.1185 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12054 to 0.11851, saving model to saved_models/weights6.hdf5\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0827 - acc: 0.9743 - val_loss: 0.1186 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0825 - acc: 0.9748 - val_loss: 0.1184 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.11851 to 0.11840, saving model to saved_models/weights6.hdf5\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0800 - acc: 0.9754 - val_loss: 0.1191 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0767 - acc: 0.9754 - val_loss: 0.1318 - val_acc: 0.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0785 - acc: 0.9798 - val_loss: 0.1146 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11840 to 0.11462, saving model to saved_models/weights6.hdf5\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0754 - acc: 0.9787 - val_loss: 0.1151 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0758 - acc: 0.9759 - val_loss: 0.1159 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0716 - acc: 0.9803 - val_loss: 0.1127 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.11462 to 0.11269, saving model to saved_models/weights6.hdf5\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0710 - acc: 0.9792 - val_loss: 0.1178 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0701 - acc: 0.9792 - val_loss: 0.1139 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0675 - acc: 0.9803 - val_loss: 0.1094 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11269 to 0.10941, saving model to saved_models/weights6.hdf5\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0680 - acc: 0.9809 - val_loss: 0.1096 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0673 - acc: 0.9781 - val_loss: 0.1073 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.10941 to 0.10726, saving model to saved_models/weights6.hdf5\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0639 - acc: 0.9836 - val_loss: 0.1208 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0647 - acc: 0.9820 - val_loss: 0.1077 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0620 - acc: 0.9836 - val_loss: 0.1404 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0642 - acc: 0.9814 - val_loss: 0.1111 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0595 - acc: 0.9847 - val_loss: 0.1027 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.10726 to 0.10268, saving model to saved_models/weights6.hdf5\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0601 - acc: 0.9836 - val_loss: 0.1096 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0585 - acc: 0.9863 - val_loss: 0.1089 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0567 - acc: 0.9847 - val_loss: 0.1129 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0575 - acc: 0.9852 - val_loss: 0.1026 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.10268 to 0.10256, saving model to saved_models/weights6.hdf5\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0561 - acc: 0.9841 - val_loss: 0.1013 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.10256 to 0.10129, saving model to saved_models/weights6.hdf5\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0569 - acc: 0.9847 - val_loss: 0.1019 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0530 - acc: 0.9880 - val_loss: 0.0981 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.10129 to 0.09814, saving model to saved_models/weights6.hdf5\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0518 - acc: 0.9885 - val_loss: 0.1068 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0511 - acc: 0.9841 - val_loss: 0.0978 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09814 to 0.09777, saving model to saved_models/weights6.hdf5\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0513 - acc: 0.9869 - val_loss: 0.1050 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0502 - acc: 0.9874 - val_loss: 0.1184 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0500 - acc: 0.9858 - val_loss: 0.1168 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0501 - acc: 0.9863 - val_loss: 0.0959 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09777 to 0.09593, saving model to saved_models/weights6.hdf5\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0473 - acc: 0.9913 - val_loss: 0.1020 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0477 - acc: 0.9874 - val_loss: 0.0948 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09593 to 0.09484, saving model to saved_models/weights6.hdf5\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0471 - acc: 0.9874 - val_loss: 0.0944 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09484 to 0.09436, saving model to saved_models/weights6.hdf5\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0458 - acc: 0.9869 - val_loss: 0.1556 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0471 - acc: 0.9869 - val_loss: 0.0939 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09436 to 0.09393, saving model to saved_models/weights6.hdf5\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0442 - acc: 0.9885 - val_loss: 0.0937 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.09393 to 0.09368, saving model to saved_models/weights6.hdf5\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0445 - acc: 0.9907 - val_loss: 0.1070 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0433 - acc: 0.9896 - val_loss: 0.1132 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0435 - acc: 0.9885 - val_loss: 0.1068 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0412 - acc: 0.9923 - val_loss: 0.0978 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0423 - acc: 0.9891 - val_loss: 0.0923 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.09368 to 0.09231, saving model to saved_models/weights6.hdf5\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0413 - acc: 0.9929 - val_loss: 0.0943 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0419 - acc: 0.9902 - val_loss: 0.0900 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.09231 to 0.08999, saving model to saved_models/weights6.hdf5\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0393 - acc: 0.9929 - val_loss: 0.0961 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0402 - acc: 0.9907 - val_loss: 0.1026 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0379 - acc: 0.9929 - val_loss: 0.1091 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0385 - acc: 0.9923 - val_loss: 0.0886 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.08999 to 0.08859, saving model to saved_models/weights6.hdf5\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0366 - acc: 0.9929 - val_loss: 0.0925 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0364 - acc: 0.9918 - val_loss: 0.1206 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0366 - acc: 0.9918 - val_loss: 0.0885 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.08859 to 0.08848, saving model to saved_models/weights6.hdf5\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0351 - acc: 0.9929 - val_loss: 0.0902 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0357 - acc: 0.9934 - val_loss: 0.0989 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0349 - acc: 0.9934 - val_loss: 0.0882 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.08848 to 0.08818, saving model to saved_models/weights6.hdf5\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0333 - acc: 0.9934 - val_loss: 0.0880 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.08818 to 0.08797, saving model to saved_models/weights6.hdf5\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9907 - val_loss: 0.0969 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0330 - acc: 0.9945 - val_loss: 0.0853 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.08797 to 0.08534, saving model to saved_models/weights6.hdf5\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0345 - acc: 0.9940 - val_loss: 0.0877 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0314 - acc: 0.9945 - val_loss: 0.0921 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0331 - acc: 0.9929 - val_loss: 0.0882 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0306 - acc: 0.9951 - val_loss: 0.0870 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0303 - acc: 0.9951 - val_loss: 0.0842 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.08534 to 0.08416, saving model to saved_models/weights6.hdf5\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0303 - acc: 0.9967 - val_loss: 0.0918 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0301 - acc: 0.9962 - val_loss: 0.0825 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.08416 to 0.08251, saving model to saved_models/weights6.hdf5\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0295 - acc: 0.9945 - val_loss: 0.0866 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0293 - acc: 0.9967 - val_loss: 0.0840 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0277 - acc: 0.9962 - val_loss: 0.0832 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0276 - acc: 0.9951 - val_loss: 0.0867 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0277 - acc: 0.9945 - val_loss: 0.0909 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "LOSS:\t0.08251497509769068 \t ACCURACY:\t0.9628008840120595\n",
      "[0.08251497509769068, 0.9628008840120595]\n",
      "    6 | 05m18s |    0.96280 |     120.4625 |     1.0000 |        0.0500 |    0.0000 |    0.0000 |   100.0000 | \n",
      "x_max [7.1044455e+01 0.0000000e+00 1.0000000e+02 1.0000000e+00 1.0000000e-05\n",
      " 5.0000000e-02]\n",
      "iteration: 7\n",
      "decay step percentage 0.05\n",
      "decay steps 5.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.6940 - acc: 0.6058 - val_loss: 0.5609 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56086, saving model to saved_models/weights7.hdf5\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.4618 - acc: 0.7988 - val_loss: 0.4228 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56086 to 0.42284, saving model to saved_models/weights7.hdf5\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.3490 - acc: 0.8666 - val_loss: 0.3356 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42284 to 0.33561, saving model to saved_models/weights7.hdf5\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.2780 - acc: 0.9147 - val_loss: 0.2863 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33561 to 0.28635, saving model to saved_models/weights7.hdf5\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.2337 - acc: 0.9322 - val_loss: 0.2465 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28635 to 0.24654, saving model to saved_models/weights7.hdf5\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.2015 - acc: 0.9426 - val_loss: 0.2177 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.24654 to 0.21768, saving model to saved_models/weights7.hdf5\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1810 - acc: 0.9464 - val_loss: 0.1986 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21768 to 0.19857, saving model to saved_models/weights7.hdf5\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1637 - acc: 0.9552 - val_loss: 0.1863 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19857 to 0.18631, saving model to saved_models/weights7.hdf5\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1502 - acc: 0.9563 - val_loss: 0.1791 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18631 to 0.17911, saving model to saved_models/weights7.hdf5\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1411 - acc: 0.9590 - val_loss: 0.1634 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.17911 to 0.16339, saving model to saved_models/weights7.hdf5\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1310 - acc: 0.9601 - val_loss: 0.1724 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1258 - acc: 0.9606 - val_loss: 0.1516 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.16339 to 0.15159, saving model to saved_models/weights7.hdf5\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1184 - acc: 0.9639 - val_loss: 0.1454 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.15159 to 0.14543, saving model to saved_models/weights7.hdf5\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.1132 - acc: 0.9672 - val_loss: 0.1450 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.14543 to 0.14496, saving model to saved_models/weights7.hdf5\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1078 - acc: 0.9688 - val_loss: 0.1548 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.1041 - acc: 0.9699 - val_loss: 0.1349 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.14496 to 0.13487, saving model to saved_models/weights7.hdf5\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0992 - acc: 0.9732 - val_loss: 0.1351 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0959 - acc: 0.9721 - val_loss: 0.1300 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.13487 to 0.12998, saving model to saved_models/weights7.hdf5\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0925 - acc: 0.9716 - val_loss: 0.1290 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.12998 to 0.12903, saving model to saved_models/weights7.hdf5\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0907 - acc: 0.9732 - val_loss: 0.1254 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.12903 to 0.12544, saving model to saved_models/weights7.hdf5\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0870 - acc: 0.9748 - val_loss: 0.1320 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0834 - acc: 0.9738 - val_loss: 0.1286 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0825 - acc: 0.9759 - val_loss: 0.1204 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.12544 to 0.12041, saving model to saved_models/weights7.hdf5\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0807 - acc: 0.9759 - val_loss: 0.1192 - val_acc: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss improved from 0.12041 to 0.11923, saving model to saved_models/weights7.hdf5\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0772 - acc: 0.9792 - val_loss: 0.1180 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11923 to 0.11796, saving model to saved_models/weights7.hdf5\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0752 - acc: 0.9776 - val_loss: 0.1167 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.11796 to 0.11669, saving model to saved_models/weights7.hdf5\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0740 - acc: 0.9803 - val_loss: 0.1198 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0719 - acc: 0.9792 - val_loss: 0.1175 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0707 - acc: 0.9787 - val_loss: 0.1304 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0683 - acc: 0.9814 - val_loss: 0.1274 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0677 - acc: 0.9814 - val_loss: 0.1198 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0654 - acc: 0.9825 - val_loss: 0.1109 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11669 to 0.11091, saving model to saved_models/weights7.hdf5\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0646 - acc: 0.9836 - val_loss: 0.1098 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.11091 to 0.10983, saving model to saved_models/weights7.hdf5\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0613 - acc: 0.9820 - val_loss: 0.1133 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0597 - acc: 0.9874 - val_loss: 0.1135 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0605 - acc: 0.9847 - val_loss: 0.1074 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.10983 to 0.10739, saving model to saved_models/weights7.hdf5\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0581 - acc: 0.9847 - val_loss: 0.1162 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0586 - acc: 0.9869 - val_loss: 0.1056 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.10739 to 0.10562, saving model to saved_models/weights7.hdf5\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0546 - acc: 0.9885 - val_loss: 0.1120 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0547 - acc: 0.9863 - val_loss: 0.1094 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0520 - acc: 0.9907 - val_loss: 0.1211 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0542 - acc: 0.9869 - val_loss: 0.1067 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0506 - acc: 0.9880 - val_loss: 0.1021 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.10562 to 0.10211, saving model to saved_models/weights7.hdf5\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0508 - acc: 0.9891 - val_loss: 0.1026 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0503 - acc: 0.9869 - val_loss: 0.1018 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.10211 to 0.10184, saving model to saved_models/weights7.hdf5\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0487 - acc: 0.9874 - val_loss: 0.1009 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.10184 to 0.10090, saving model to saved_models/weights7.hdf5\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0484 - acc: 0.9891 - val_loss: 0.1010 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0458 - acc: 0.9885 - val_loss: 0.1056 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0455 - acc: 0.9885 - val_loss: 0.1017 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0455 - acc: 0.9891 - val_loss: 0.1000 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10090 to 0.10003, saving model to saved_models/weights7.hdf5\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0436 - acc: 0.9896 - val_loss: 0.0988 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.10003 to 0.09877, saving model to saved_models/weights7.hdf5\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0434 - acc: 0.9913 - val_loss: 0.0975 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.09877 to 0.09746, saving model to saved_models/weights7.hdf5\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0425 - acc: 0.9918 - val_loss: 0.0968 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.09746 to 0.09678, saving model to saved_models/weights7.hdf5\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0412 - acc: 0.9896 - val_loss: 0.0981 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0418 - acc: 0.9891 - val_loss: 0.0978 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0394 - acc: 0.9913 - val_loss: 0.0976 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0400 - acc: 0.9907 - val_loss: 0.0976 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0386 - acc: 0.9913 - val_loss: 0.0943 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09678 to 0.09431, saving model to saved_models/weights7.hdf5\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 2s 1ms/step - loss: 0.0370 - acc: 0.9918 - val_loss: 0.0952 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0373 - acc: 0.9918 - val_loss: 0.0990 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0374 - acc: 0.9907 - val_loss: 0.0932 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09431 to 0.09318, saving model to saved_models/weights7.hdf5\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0363 - acc: 0.9918 - val_loss: 0.0974 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0341 - acc: 0.9929 - val_loss: 0.1025 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0344 - acc: 0.9940 - val_loss: 0.0916 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.09318 to 0.09160, saving model to saved_models/weights7.hdf5\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0347 - acc: 0.9923 - val_loss: 0.0911 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.09160 to 0.09110, saving model to saved_models/weights7.hdf5\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0327 - acc: 0.9945 - val_loss: 0.0909 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09110 to 0.09094, saving model to saved_models/weights7.hdf5\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0324 - acc: 0.9929 - val_loss: 0.0919 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0322 - acc: 0.9929 - val_loss: 0.0932 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0322 - acc: 0.9934 - val_loss: 0.0898 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.09094 to 0.08976, saving model to saved_models/weights7.hdf5\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9940 - val_loss: 0.0919 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0309 - acc: 0.9940 - val_loss: 0.0891 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08976 to 0.08914, saving model to saved_models/weights7.hdf5\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0293 - acc: 0.9967 - val_loss: 0.0894 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0294 - acc: 0.9951 - val_loss: 0.0885 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08914 to 0.08854, saving model to saved_models/weights7.hdf5\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0278 - acc: 0.9956 - val_loss: 0.0886 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0283 - acc: 0.9956 - val_loss: 0.0879 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08854 to 0.08791, saving model to saved_models/weights7.hdf5\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0275 - acc: 0.9956 - val_loss: 0.0874 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08791 to 0.08740, saving model to saved_models/weights7.hdf5\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0269 - acc: 0.9951 - val_loss: 0.0877 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0269 - acc: 0.9962 - val_loss: 0.0868 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.08740 to 0.08678, saving model to saved_models/weights7.hdf5\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0260 - acc: 0.9962 - val_loss: 0.0920 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0259 - acc: 0.9967 - val_loss: 0.0887 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0250 - acc: 0.9962 - val_loss: 0.0880 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0240 - acc: 0.9984 - val_loss: 0.0861 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.08678 to 0.08609, saving model to saved_models/weights7.hdf5\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0253 - acc: 0.9967 - val_loss: 0.0860 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.08609 to 0.08596, saving model to saved_models/weights7.hdf5\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0244 - acc: 0.9945 - val_loss: 0.0864 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0238 - acc: 0.9973 - val_loss: 0.0850 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.08596 to 0.08504, saving model to saved_models/weights7.hdf5\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0234 - acc: 0.9978 - val_loss: 0.0846 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.08504 to 0.08465, saving model to saved_models/weights7.hdf5\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0230 - acc: 0.9967 - val_loss: 0.0847 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0226 - acc: 0.9973 - val_loss: 0.0844 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.08465 to 0.08438, saving model to saved_models/weights7.hdf5\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0215 - acc: 0.9978 - val_loss: 0.0885 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0220 - acc: 0.9984 - val_loss: 0.0837 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.08438 to 0.08368, saving model to saved_models/weights7.hdf5\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 1ms/step - loss: 0.0214 - acc: 0.9967 - val_loss: 0.0859 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9978 - val_loss: 0.0866 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0207 - acc: 0.9973 - val_loss: 0.0822 - val_acc: 0.9737\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.08368 to 0.08217, saving model to saved_models/weights7.hdf5\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0195 - acc: 0.9984 - val_loss: 0.0826 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0191 - acc: 0.9984 - val_loss: 0.0870 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0194 - acc: 0.9989 - val_loss: 0.0866 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0189 - acc: 0.9978 - val_loss: 0.0886 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0185 - acc: 0.9978 - val_loss: 0.0925 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0183 - acc: 0.9984 - val_loss: 0.0824 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 0.0825 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "LOSS:\t0.08217482833309951 \t ACCURACY:\t0.9737417922239074\n",
      "[0.08217482833309951, 0.9737417922239074]\n",
      "    7 | 06m10s | \u001b[35m   0.97374\u001b[0m | \u001b[32m     71.0445\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m       0.0500\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m  100.0000\u001b[0m | \n",
      "x_max [5.67087271e+01 0.00000000e+00 7.33842801e+01 1.00000000e+00\n",
      " 1.00000000e-05 5.00000000e-02]\n",
      "iteration: 8\n",
      "decay step percentage 0.05\n",
      "decay steps 4.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/73\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.6184 - acc: 0.6638 - val_loss: 0.4695 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46948, saving model to saved_models/weights8.hdf5\n",
      "Epoch 2/73\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.4016 - acc: 0.8305 - val_loss: 0.3555 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46948 to 0.35555, saving model to saved_models/weights8.hdf5\n",
      "Epoch 3/73\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.3041 - acc: 0.9032 - val_loss: 0.2828 - val_acc: 0.8972\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35555 to 0.28282, saving model to saved_models/weights8.hdf5\n",
      "Epoch 4/73\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.2494 - acc: 0.9207 - val_loss: 0.2472 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28282 to 0.24722, saving model to saved_models/weights8.hdf5\n",
      "Epoch 5/73\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.2126 - acc: 0.9328 - val_loss: 0.2124 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.24722 to 0.21241, saving model to saved_models/weights8.hdf5\n",
      "Epoch 6/73\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1876 - acc: 0.9344 - val_loss: 0.1972 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21241 to 0.19717, saving model to saved_models/weights8.hdf5\n",
      "Epoch 7/73\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1691 - acc: 0.9399 - val_loss: 0.1830 - val_acc: 0.9278\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19717 to 0.18298, saving model to saved_models/weights8.hdf5\n",
      "Epoch 8/73\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1556 - acc: 0.9481 - val_loss: 0.1662 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18298 to 0.16622, saving model to saved_models/weights8.hdf5\n",
      "Epoch 9/73\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1431 - acc: 0.9530 - val_loss: 0.1586 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.16622 to 0.15857, saving model to saved_models/weights8.hdf5\n",
      "Epoch 10/73\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1336 - acc: 0.9563 - val_loss: 0.1507 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15857 to 0.15074, saving model to saved_models/weights8.hdf5\n",
      "Epoch 11/73\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1238 - acc: 0.9612 - val_loss: 0.1447 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15074 to 0.14474, saving model to saved_models/weights8.hdf5\n",
      "Epoch 12/73\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1167 - acc: 0.9623 - val_loss: 0.1470 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/73\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1109 - acc: 0.9650 - val_loss: 0.1442 - val_acc: 0.9344\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.14474 to 0.14420, saving model to saved_models/weights8.hdf5\n",
      "Epoch 14/73\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1067 - acc: 0.9650 - val_loss: 0.1309 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.14420 to 0.13089, saving model to saved_models/weights8.hdf5\n",
      "Epoch 15/73\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.1023 - acc: 0.9688 - val_loss: 0.1308 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.13089 to 0.13081, saving model to saved_models/weights8.hdf5\n",
      "Epoch 16/73\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0967 - acc: 0.9699 - val_loss: 0.1268 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.13081 to 0.12677, saving model to saved_models/weights8.hdf5\n",
      "Epoch 17/73\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0938 - acc: 0.9688 - val_loss: 0.1273 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/73\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0902 - acc: 0.9721 - val_loss: 0.1224 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.12677 to 0.12238, saving model to saved_models/weights8.hdf5\n",
      "Epoch 19/73\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0870 - acc: 0.9748 - val_loss: 0.1216 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.12238 to 0.12155, saving model to saved_models/weights8.hdf5\n",
      "Epoch 20/73\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0846 - acc: 0.9743 - val_loss: 0.1315 - val_acc: 0.9300\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/73\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0818 - acc: 0.9743 - val_loss: 0.1303 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/73\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0799 - acc: 0.9738 - val_loss: 0.1174 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.12155 to 0.11745, saving model to saved_models/weights8.hdf5\n",
      "Epoch 23/73\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0760 - acc: 0.9814 - val_loss: 0.1153 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.11745 to 0.11534, saving model to saved_models/weights8.hdf5\n",
      "Epoch 24/73\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0765 - acc: 0.9743 - val_loss: 0.1157 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/73\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0731 - acc: 0.9765 - val_loss: 0.1123 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11534 to 0.11234, saving model to saved_models/weights8.hdf5\n",
      "Epoch 26/73\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0723 - acc: 0.9765 - val_loss: 0.1162 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/73\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0682 - acc: 0.9776 - val_loss: 0.1091 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11234 to 0.10906, saving model to saved_models/weights8.hdf5\n",
      "Epoch 28/73\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0684 - acc: 0.9787 - val_loss: 0.1097 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/73\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0648 - acc: 0.9803 - val_loss: 0.1097 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/73\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0641 - acc: 0.9809 - val_loss: 0.1079 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.10906 to 0.10794, saving model to saved_models/weights8.hdf5\n",
      "Epoch 31/73\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0623 - acc: 0.9852 - val_loss: 0.1060 - val_acc: 0.9562\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.10794 to 0.10604, saving model to saved_models/weights8.hdf5\n",
      "Epoch 32/73\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0606 - acc: 0.9803 - val_loss: 0.1049 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.10604 to 0.10494, saving model to saved_models/weights8.hdf5\n",
      "Epoch 33/73\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0593 - acc: 0.9825 - val_loss: 0.1050 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/73\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0573 - acc: 0.9863 - val_loss: 0.1035 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.10494 to 0.10354, saving model to saved_models/weights8.hdf5\n",
      "Epoch 35/73\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0561 - acc: 0.9836 - val_loss: 0.1023 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.10354 to 0.10225, saving model to saved_models/weights8.hdf5\n",
      "Epoch 36/73\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0547 - acc: 0.9841 - val_loss: 0.1009 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.10225 to 0.10087, saving model to saved_models/weights8.hdf5\n",
      "Epoch 37/73\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0540 - acc: 0.9858 - val_loss: 0.1005 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.10087 to 0.10054, saving model to saved_models/weights8.hdf5\n",
      "Epoch 38/73\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0530 - acc: 0.9863 - val_loss: 0.1029 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/73\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0520 - acc: 0.9869 - val_loss: 0.1067 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/73\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0505 - acc: 0.9874 - val_loss: 0.1021 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/73\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0497 - acc: 0.9852 - val_loss: 0.1083 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/73\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.0496 - acc: 0.9847 - val_loss: 0.0976 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_loss improved from 0.10054 to 0.09756, saving model to saved_models/weights8.hdf5\n",
      "Epoch 43/73\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0472 - acc: 0.9885 - val_loss: 0.1025 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/73\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0465 - acc: 0.9858 - val_loss: 0.0981 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/73\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0465 - acc: 0.9880 - val_loss: 0.0964 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.09756 to 0.09637, saving model to saved_models/weights8.hdf5\n",
      "Epoch 46/73\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0436 - acc: 0.9869 - val_loss: 0.1103 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/73\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0429 - acc: 0.9907 - val_loss: 0.0974 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/73\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0428 - acc: 0.9896 - val_loss: 0.0983 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/73\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0417 - acc: 0.9891 - val_loss: 0.0937 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.09637 to 0.09373, saving model to saved_models/weights8.hdf5\n",
      "Epoch 50/73\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0396 - acc: 0.9913 - val_loss: 0.0965 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/73\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0398 - acc: 0.9896 - val_loss: 0.1048 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/73\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0382 - acc: 0.9918 - val_loss: 0.1029 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/73\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0385 - acc: 0.9923 - val_loss: 0.1029 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/73\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0375 - acc: 0.9923 - val_loss: 0.0964 - val_acc: 0.9628\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/73\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0367 - acc: 0.9896 - val_loss: 0.0946 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/73\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0350 - acc: 0.9934 - val_loss: 0.0957 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/73\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0354 - acc: 0.9907 - val_loss: 0.0916 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.09373 to 0.09160, saving model to saved_models/weights8.hdf5\n",
      "Epoch 58/73\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0341 - acc: 0.9918 - val_loss: 0.0903 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.09160 to 0.09028, saving model to saved_models/weights8.hdf5\n",
      "Epoch 59/73\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0334 - acc: 0.9929 - val_loss: 0.0896 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.09028 to 0.08960, saving model to saved_models/weights8.hdf5\n",
      "Epoch 60/73\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0321 - acc: 0.9918 - val_loss: 0.0891 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08960 to 0.08908, saving model to saved_models/weights8.hdf5\n",
      "Epoch 61/73\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0329 - acc: 0.9934 - val_loss: 0.0902 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/73\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0313 - acc: 0.9934 - val_loss: 0.1014 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/73\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0316 - acc: 0.9923 - val_loss: 0.0897 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/73\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0295 - acc: 0.9962 - val_loss: 0.0966 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/73\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0306 - acc: 0.9940 - val_loss: 0.0932 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/73\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 3s 2ms/step - loss: 0.0302 - acc: 0.9929 - val_loss: 0.0876 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08908 to 0.08756, saving model to saved_models/weights8.hdf5\n",
      "Epoch 67/73\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0291 - acc: 0.9951 - val_loss: 0.0878 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/73\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0290 - acc: 0.9929 - val_loss: 0.0889 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/73\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 4s 2ms/step - loss: 0.0275 - acc: 0.9967 - val_loss: 0.0862 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08756 to 0.08622, saving model to saved_models/weights8.hdf5\n",
      "Epoch 70/73\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0266 - acc: 0.9956 - val_loss: 0.0859 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08622 to 0.08594, saving model to saved_models/weights8.hdf5\n",
      "Epoch 71/73\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0271 - acc: 0.9945 - val_loss: 0.0849 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08594 to 0.08490, saving model to saved_models/weights8.hdf5\n",
      "Epoch 72/73\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0265 - acc: 0.9945 - val_loss: 0.1034 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/73\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 0.0256 - acc: 0.9951 - val_loss: 0.0845 - val_acc: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00073: val_loss improved from 0.08490 to 0.08446, saving model to saved_models/weights8.hdf5\n",
      "LOSS:\t0.08445664398429234 \t ACCURACY:\t0.9671772512356615\n",
      "[0.08445664398429234, 0.9671772512356615]\n",
      "    8 | 06m10s |    0.96718 |      56.7087 |     1.0000 |        0.0500 |    0.0000 |    0.0000 |    73.3843 | \n",
      "x_max [2.89758648e+01 8.00000000e-01 7.23538889e+01 1.00000000e+00\n",
      " 1.00000000e-05 5.00000000e-01]\n",
      "iteration: 9\n",
      "decay step percentage 0.5\n",
      "decay steps 36.0\n",
      "Train on 1829 samples, validate on 457 samples\n",
      "Epoch 1/72\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 10s 6ms/step - loss: 3.4734 - acc: 0.5325 - val_loss: 0.6064 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60644, saving model to saved_models/weights9.hdf5\n",
      "Epoch 2/72\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 5s 3ms/step - loss: 3.1019 - acc: 0.5440 - val_loss: 0.4827 - val_acc: 0.7330\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60644 to 0.48275, saving model to saved_models/weights9.hdf5\n",
      "Epoch 3/72\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 2.4926 - acc: 0.5910 - val_loss: 0.4038 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48275 to 0.40378, saving model to saved_models/weights9.hdf5\n",
      "Epoch 4/72\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 8s 5ms/step - loss: 1.9866 - acc: 0.6233 - val_loss: 0.2727 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40378 to 0.27266, saving model to saved_models/weights9.hdf5\n",
      "Epoch 5/72\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 1.5901 - acc: 0.6495 - val_loss: 0.2853 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/72\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 1.4390 - acc: 0.6698 - val_loss: 0.2983 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/72\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 1.1110 - acc: 0.6933 - val_loss: 0.2160 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27266 to 0.21601, saving model to saved_models/weights9.hdf5\n",
      "Epoch 8/72\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.7752 - acc: 0.7551 - val_loss: 0.1895 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21601 to 0.18946, saving model to saved_models/weights9.hdf5\n",
      "Epoch 9/72\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.6963 - acc: 0.7758 - val_loss: 0.2024 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/72\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.6007 - acc: 0.7890 - val_loss: 0.1845 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18946 to 0.18447, saving model to saved_models/weights9.hdf5\n",
      "Epoch 11/72\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.4875 - acc: 0.8234 - val_loss: 0.1738 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18447 to 0.17379, saving model to saved_models/weights9.hdf5\n",
      "Epoch 12/72\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 8s 4ms/step - loss: 0.4336 - acc: 0.8338 - val_loss: 0.1613 - val_acc: 0.9431\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17379 to 0.16131, saving model to saved_models/weights9.hdf5\n",
      "Epoch 13/72\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.3870 - acc: 0.8475 - val_loss: 0.1693 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/72\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 7s 4ms/step - loss: 0.3380 - acc: 0.8606 - val_loss: 0.1548 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.16131 to 0.15483, saving model to saved_models/weights9.hdf5\n",
      "Epoch 15/72\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "1829/1829 [==============================] - 6s 3ms/step - loss: 0.2963 - acc: 0.8814 - val_loss: 0.1573 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/72\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
      " 392/1829 [=====>........................] - ETA: 4s - loss: 0.2769 - acc: 0.9031"
     ]
    }
   ],
   "source": [
    "import bayes_opt\n",
    "\n",
    "itr = 0\n",
    "all_params = []\n",
    "opt_model = bayes_opt.BayesianOptimization(f, bounds)\n",
    "opt_model.maximize(n_iter=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "best_itr = 'unknown'\n",
    "for i in range(len(all_params)):\n",
    "    if all_params[i]==opt_model.res['max']['max_params']:\n",
    "        best_itr = i\n",
    "\n",
    "print(best_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {'max_params': {'batch_size': 68.91979061160433, 'drpout': 0.5963357286154068, 'n_epochs': 53.41219205767776, 'decay_rt': 0.3198907175402304, 'lrt': 0.00011921968313972895, 'decay_steps': 0.3798176479018959}, 'max_val': 0.9671772444535136}\n"
     ]
    }
   ],
   "source": [
    "print('Results:', opt_model.res['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(model_save_folder+'/weights'+str(best_itr+1)+'.hdf5',model_save_folder+'/best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_size', 'drpout', 'n_epochs', 'values', 'decay_rt', 'lrt', 'decay_steps', 'values']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "fieldnames = []\n",
    "for key, value in opt_model.res['all']['params'][0].items():\n",
    "    fieldnames.append(key)\n",
    "fieldnames.append('values')\n",
    "\n",
    "print(fieldnames)\n",
    "\n",
    "with open('parameters.csv', 'w') as csvfile:\n",
    "    row = opt_model.res['all']['params'][0]\n",
    "    row['values'] = opt_model.res['all']['values'][0]\n",
    "    row['test'] = 1\n",
    "    fieldnames = []\n",
    "    for key, value in row.items():\n",
    "        fieldnames.append(key)\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for itr in range(1,len(opt_model.res['all']['params'])):\n",
    "        row = opt_model.res['all']['params'][itr]\n",
    "        row['values'] = opt_model.res['all']['values'][itr]\n",
    "        row['test'] = 1\n",
    "        writer.writerow(row)\n",
    "#    writer.writerow({'first_name': 'Lovely', 'last_name': 'Spam'})\n",
    "#    writer.writerow({'first_name': 'Wonderful', 'last_name': 'Spam'})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('parameters.csv')\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import parallel_coordinates\n",
    "plt.figure()\n",
    "parallel_coordinates(data,'test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
